# SAM3 LoRA Configuration for Crack Detection
# This config enables text encoder training for better text prompt support

# Model settings
model:
  name: "facebook/sam3"
  cache_dir: null

# LoRA settings
lora:
  rank: 16                    # Higher rank for better adaptation
  alpha: 32                   # 2x rank
  dropout: 0.1

  # Target modules
  target_modules:
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "out_proj"
    - "fc1"
    - "fc2"

  # IMPORTANT: Enable text encoder for text prompt support!
  apply_to_vision_encoder: true     # For visual features
  apply_to_text_encoder: true       # ENABLED - for text prompts!
  apply_to_geometry_encoder: false
  apply_to_detr_encoder: false
  apply_to_detr_decoder: false
  apply_to_mask_decoder: true       # For mask generation

# Training settings
training:
  train_data_path: "data/train"
  val_data_path: "data/valid"
  batch_size: 1                # Start small
  num_workers: 4

  learning_rate: 1e-4          # Higher LR to start
  weight_decay: 0.01
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_epsilon: 1e-8
  max_grad_norm: 1.0

  num_epochs: 50                # More epochs
  warmup_steps: 100
  lr_scheduler: "cosine"

  logging_steps: 10
  eval_steps: 200
  save_steps: 500
  save_total_limit: 3

  mixed_precision: "bf16"
  seed: 42
  gradient_accumulation_steps: 2

output:
  output_dir: "outputs/crack_detection_lora"
  logging_dir: "logs/crack_detection"
  save_lora_only: true
  push_to_hub: false
  hub_model_id: null

evaluation:
  metric: "iou"
  save_predictions: false
  compute_metrics_during_training: true

hardware:
  device: "cuda"
  dataloader_pin_memory: true
  use_compile: false
